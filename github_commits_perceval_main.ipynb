{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\n",
    "import sys\n",
    "import modin.pandas as modinpd\n",
    "import pandas as pd\n",
    "from perceval.backends.core.git import Git\n",
    "from models.model_Commits import Commits\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import types as sqltype\n",
    "from config.database import HOST, PORT, USER, PASSWORD, DATABASE\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "import gc"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UserWarning: Modin Ray engine was started with 3 GB free space avaliable, if it is not enough for your application, please set environment variable MODIN_ON_RAY_PLASMA_DIR=/directory/without/space/limiting\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def add_aliase(aliase_id, mailaddress, source):\n",
    "\n",
    "    try:\n",
    "        db = psycopg2.connect(\n",
    "            host=HOST,\n",
    "            port=PORT,\n",
    "            user=USER,\n",
    "            password=PASSWORD,\n",
    "            database=DATABASE)\n",
    "            #charset='utf8')\n",
    "        cursor = db.cursor()\n",
    "    except Exception as e:\n",
    "        logging.error(\"Database connect error:%s\" % e)\n",
    "\n",
    "    #aliase_id, mailaddress = aliase.replace('<', ' ').replace('>', ' ').split()\n",
    "    aliase_id = aliase_id.replace('\\'','\\'\\'')\n",
    "    sql_aliase = \"\"\"INSERT INTO aliase(aliase_id, mailaddress, source)\n",
    "                                        values('%s', '%s', '%s')\"\"\" % (aliase_id, mailaddress, source)\n",
    "    try:\n",
    "        db.commit()\n",
    "        cursor.execute(sql_aliase)\n",
    "        db.commit()\n",
    "    except Exception as err:\n",
    "        sql_aliase = \"\"\"UPDATE aliase SET mailaddress='%s', source='%s' WHERE aliase_id='%s' \"\"\" % (mailaddress, source, aliase_id)\n",
    "        #print(err)\n",
    "        pass\n",
    "    return aliase_id\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.read_csv(\"../gitrepository_sub.csv\")\n",
    "github_source_url = df[\"Repos\"].values[405:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "github_source_url[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://github.com/OSGeo/grass'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "for url in github_source_url:\n",
    "    repo_url = url\n",
    "    counter = 0\n",
    "    # directory for letting Perceval clone the git repo\n",
    "    repolast = url.split('/')[-1]\n",
    "    proj_name = str(df.loc[df[\"Repos\"] == url.replace('/issues', '')][\"Projects\"].values[0]).lower()\n",
    "    repo_name = repo_url.split('/')[-1]\n",
    "    repo_dir = '/mnt/data0/proj_osgeo/temp/'+proj_name+'/'+str(repolast)+'.git'\n",
    "    \n",
    "\n",
    "    # create a Git object, pointing to repo_url, using repo_dir for cloning\n",
    "    repo = Git(uri=repo_url, gitpath=repo_dir)\n",
    "    repo_data = repo.fetch()\n",
    "    print(\"Succesfully get repo:\"+repo_dir)\n",
    "    #print(type(repo_data))\n",
    "    # Fetch return a generator\n",
    "    \n",
    "    ####fw = open('./repo_fetch.json','w')\n",
    "    ###fw.write('{\\\"all_commits\\\":[')\n",
    "    \n",
    "    all_commits = []\n",
    "\n",
    "    # fetch all commits as an iterator, and iterate it printing each hash\n",
    "    \n",
    "    for commit in repo_data:\n",
    "        counter += 1\n",
    "        commit['data']['proj_id'] = proj_name\n",
    "        commit['data']['repo'] = repo_name\n",
    "        commit['data']['commit_id'] = proj_name+\"#\"+repo_name+\"#\"+str(counter)+\"#\"+commit['data']['commit']\n",
    "        \n",
    "        try:\n",
    "            author= commit['data']['Author'].replace('<', ' ').replace('>', ' ').split()[0]\n",
    "            author_email= commit['data']['Author'].replace('<', ' ').replace('>', ' ').split()[-1]\n",
    "            commiter= commit['data']['Commit'].replace('<', ' ').replace('>', ' ').split()[0]\n",
    "            commiter_email= commit['data']['Commit'].replace('<', ' ').replace('>', ' ').split()[-1]\n",
    "            if author == author_email :\n",
    "                author_email = \"\"\n",
    "            if commiter == commiter_email:\n",
    "                commiter_email = \"\"\n",
    "            commit['data']['author_id'] = author\n",
    "            commit['data']['author_email'] =  author_email\n",
    "            commit['data']['commiter_id'] = commiter\n",
    "            commit['data']['commiter_email'] = commiter_email\n",
    "        except IndexError as e:\n",
    "            print(commit['data']['Author'])\n",
    "            print(commit['data']['Commit'])\n",
    "\n",
    "        all_commits.append(commit['data'])\n",
    "\n",
    "    print(\"Get all commits:\", counter)\n",
    "    df_all_commits = pd.DataFrame(all_commits)\n",
    "    df_all_commits = df_all_commits[['commit', 'parents', 'refs', 'Author', 'AuthorDate', 'Commit',\n",
    "       'CommitDate', 'message', 'files', 'proj_id', 'repo', 'commit_id',\n",
    "       'author_id', 'author_email', 'commiter_id', 'commiter_email']]\n",
    "\n",
    "    df_all_commits.columns = ['commit_sha', 'commit_parents', 'commit_refs', 'author', 'author_timestamp', 'commiter',\n",
    "       'commit_timestamp', 'commit_message', 'files', 'proj_id', 'repo', 'commit_id','author_aliase_id', 'author_email', 'commiter_aliase_id', 'commiter_email'] \n",
    "    \n",
    "    df_all_commits['commit_timestamp'].apply(lambda x: pd.Timestamp(x))\n",
    "    df_all_commits['author_timestamp'].apply(lambda x: pd.Timestamp(x))\n",
    "\n",
    "    df_psql_commits = df_all_commits[['commit_id','proj_id','author_aliase_id', 'author_timestamp', \n",
    "    'commiter_aliase_id', 'commit_timestamp', 'commit_message', 'commit_sha', 'commit_parents', 'commit_refs']].astype(str)\n",
    "\n",
    "    df_psql_aliases = pd.DataFrame()\n",
    "    df_psql_aliases['aliase_id'] = df_psql_commits['author_aliase_id'].append(df_psql_commits['commiter_aliase_id'], ignore_index=True)\n",
    "    df_psql_aliases['mailaddress'] = df_all_commits['author_email'].append(df_all_commits['commiter_email'], ignore_index=True)\n",
    "    df_psql_aliases = df_psql_aliases.drop_duplicates().astype(str)\n",
    "    df_psql_aliases['source'] = 'Github'\n",
    "\n",
    "    df_psql_aliases['source'] = 'Github'\n",
    "    for col in df_psql_aliases.columns.values :\n",
    "        df_psql_aliases[col]= df_psql_aliases[col].apply(lambda x : x.encode('utf-8','ignore').decode(\"utf-8\"))\n",
    "    for aliase_id, mailaddress, source in df_psql_aliases.values :\n",
    "        #print(aliase_id, mailaddress, source)\n",
    "        add_aliase(aliase_id, mailaddress, source)\n",
    "    print(\"aliase updated\")\n",
    "    #continue   #USE TO UPDATE ALL ALIASES!!!!!!\n",
    "\n",
    "    all_filelogs = []\n",
    "    file_counter = 0\n",
    "    for filelog, commit_id, proj, repo in (df_all_commits[[\"files\",\"commit_id\",\"proj_id\",\"repo\"]].values):\n",
    "        for log in filelog:\n",
    "            file_counter+=1\n",
    "            log['commit_id'] = commit_id\n",
    "            log['id'] = proj+\"#\"+repo+\"#\"+str(file_counter)+\"#\"+log['file']\n",
    "            #log['mode_before']= log['modes'][0]\n",
    "            #log['mode_after']= log['modes'][-1]\n",
    "        all_filelogs += filelog\n",
    "        #print(filelog)\n",
    "        #break\n",
    "        \n",
    "    df_all_filelogs = pd.DataFrame(all_filelogs)\n",
    "    df_all_filelogs = df_all_filelogs[['modes', 'indexes', 'action', 'file', 'added', 'removed', 'commit_id', 'id']]\n",
    "    print(\"Get all filelogs:\", file_counter)\n",
    "\n",
    "    df_all_filelogs.columns = ['modes', 'indexes', 'action', 'file_name', 'added', 'removed', 'commit_id',\n",
    "       'filelog_id']\n",
    "    \n",
    "    df_psql_filelogs = df_all_filelogs[['filelog_id', 'commit_id', 'modes', 'indexes', 'action', 'file_name', 'added', 'removed']].astype(str)\n",
    "\n",
    "    psql_engine = create_engine(\"postgresql://\"+USER+\":\"+PASSWORD+\"@\"+HOST+\":\"+str(PORT)+\"/\"+DATABASE)\n",
    "\n",
    "\n",
    "    for col in df_psql_commits.columns.values :\n",
    "        df_psql_commits[col]= df_psql_commits[col].apply(lambda x : x.encode('utf-8','ignore').decode(\"utf-8\"))\n",
    "    try:\n",
    "        df_psql_commits.to_sql(name='commit', con = psql_engine, if_exists= 'append', index= False)\n",
    "        print(\"commit added\")\n",
    "    except BaseException as err:\n",
    "        print(err)\n",
    "    \n",
    "    try:\n",
    "        df_psql_filelogs.to_sql(name='filelog', con = psql_engine, if_exists= 'append', index= False)\n",
    "        print(\"filelogs added\")\n",
    "    except BaseException as err:\n",
    "        print(err)\n",
    "        \n",
    "    del df_all_commits, df_all_filelogs, df_psql_aliases, df_psql_commits, df_psql_filelogs\n",
    "    gc.collect()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Succesfully get repo:/mnt/data0/proj_osgeo/temp/grass/grass.git\n",
      "Get all commits: 49671\n",
      "aliase updated\n",
      "Get all filelogs: 222802\n",
      "commit added\n",
      "filelogs added\n",
      "Succesfully get repo:/mnt/data0/proj_osgeo/temp/grass/grass-website.git\n",
      "Get all commits: 461\n",
      "aliase updated\n",
      "Get all filelogs: 2827\n",
      "commit added\n",
      "filelogs added\n",
      "Succesfully get repo:/mnt/data0/proj_osgeo/temp/grass/grass-addons.git\n",
      "Get all commits: 8155\n",
      "aliase updated\n",
      "Get all filelogs: 39273\n",
      "commit added\n",
      "filelogs added\n",
      "Succesfully get repo:/mnt/data0/proj_osgeo/temp/grass/grass-legacy.git\n",
      "Get all commits: 101786\n",
      "aliase updated\n",
      "Get all filelogs: 509332\n",
      "commit added\n",
      "filelogs added\n",
      "Succesfully get repo:/mnt/data0/proj_osgeo/temp/grass/grass-promo.git\n",
      "Get all commits: 323\n",
      "aliase updated\n",
      "Get all filelogs: 1991\n",
      "commit added\n",
      "filelogs added\n",
      "Succesfully get repo:/mnt/data0/proj_osgeo/temp/gdal/ogr/gdal-docs.git\n",
      "Get all commits: 1\n",
      "aliase updated\n",
      "Get all filelogs: 2462\n",
      "commit added\n",
      "filelogs added\n",
      "Succesfully get repo:/mnt/data0/proj_osgeo/temp/gdal/ogr/gdal-extra-drivers.git\n",
      "Get all commits: 16\n",
      "aliase updated\n",
      "Get all filelogs: 157\n",
      "commit added\n",
      "filelogs added\n",
      "Succesfully get repo:/mnt/data0/proj_osgeo/temp/gdal/ogr/gdal_svn_mirror_backup.git\n",
      "Get all commits: 53000\n",
      "aliase updated\n",
      "Get all filelogs: 150891\n",
      "commit added\n",
      "filelogs added\n",
      "Succesfully get repo:/mnt/data0/proj_osgeo/temp/proj/PROJ-data.git\n",
      "Get all commits: 247\n",
      "aliase updated\n",
      "Get all filelogs: 1968\n",
      "commit added\n",
      "filelogs added\n",
      "Succesfully get repo:/mnt/data0/proj_osgeo/temp/proj/proj-datumgrid.git\n",
      "Get all commits: 229\n",
      "aliase updated\n",
      "Get all filelogs: 1065\n",
      "commit added\n",
      "filelogs added\n",
      "Succesfully get repo:/mnt/data0/proj_osgeo/temp/proj/proj-coverage.git\n",
      "Get all commits: 1\n",
      "aliase updated\n",
      "Get all filelogs: 569\n",
      "commit added\n",
      "filelogs added\n",
      "Succesfully get repo:/mnt/data0/proj_osgeo/temp/proj/proj4-doc-forward.git\n",
      "Get all commits: 7\n",
      "aliase updated\n",
      "Get all filelogs: 9\n",
      "commit added\n",
      "filelogs added\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_psql_filelogs.to_sql(name='filelog', con = psql_engine, if_exists= 'append', index= False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_psql_commits.to_sql(name='commit', con = psql_engine, if_exists= 'append', index= False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_all_commits.columns.values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_all_filelogs.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_psql_commits.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for col in df_psql_commits.columns.values :\n",
    "    df_psql_commits[col]= df_psql_commits[col].apply(lambda x : x.encode('utf-8','ignore').decode(\"utf-8\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_psql_aliases = pd.DataFrame()\n",
    "\n",
    "df_psql_aliases['aliase_id'] = df_psql_commits['author_aliase_id'].append(df_psql_commits['commiter_aliase_id'], ignore_index=True)\n",
    "df_psql_aliases['mailaddress'] = df_all_commits['author_email'].append(df_all_commits['commiter_email'], ignore_index=True)\n",
    "df_psql_aliases = df_psql_aliases.drop_duplicates().astype(str)\n",
    "#df_psql_aliases = df_psql_aliases.astype(str)\n",
    "\n",
    "df_psql_aliases['source'] = 'Github'\n",
    "for col in df_psql_aliases.columns.values :\n",
    "    df_psql_aliases[col]= df_psql_aliases[col].apply(lambda x : x.encode('utf-8','ignore').decode(\"utf-8\"))\n",
    "for aliase_id, mailaddress, source in df_psql_aliases.values :\n",
    "    print(aliase_id, mailaddress, source)\n",
    "    add_aliase(aliase_id, mailaddress, source)\n",
    "print(\"aliase updated\")"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"D'Hont\" in df_psql_aliases['aliase_id'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"D'Hont\" in df_psql_aliases.values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_psql_aliases.values[100]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98373a4284e4a564d4f2df06473808b29be6466d133612bf3acd704edfd754d1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('3.6.13': pyenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}